{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, binom, poisson, uniform, expon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.special import comb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "air_path = \"/Users/student/PycharmProjects/labs/datasets/AirQualityUCI.csv\"\n",
    "\n",
    "#Data loading\n",
    "#Step 1.1 - Load the Data\n",
    "def load_data(air_path):\n",
    "    try:\n",
    "        #Data columns are separated with \";\". The sep = \";\" comment specifies this to Pandas.\n",
    "        #In the data, pandas reads the time column as object/string.\n",
    "        #The comma is a decimal separator in the data, and is converted to float with decimal = \",\".\n",
    "        df_air = pd.read_csv(air_path, sep=';', decimal=',')\n",
    "        #Converting the columns to strings, and cleaning the noise.\n",
    "        df_air.columns = df_air.columns.str.strip()\n",
    "        initial_rows = len(df_air)\n",
    "        #Replacing (-200) to NaN\n",
    "        #inplace=True, changes the current dataframe.\n",
    "        df_air.replace(to_replace=-200, value=np.nan, inplace=True)\n",
    "        #There is empty columns in the data. Axis=1 refers to the columns, Axis=0 refers to the rows. How=\"all\" specifies that only columns that are completely empty will be dropped.\n",
    "        df_air.dropna(axis=1, how='all', inplace=True)\n",
    "        subset_cols = ['T', 'RH', 'AH', 'CO(GT)']\n",
    "        df_air.dropna(subset=subset_cols, inplace=True)\n",
    "        dropped_rows = initial_rows - len(df_air)\n",
    "        print(\"--- Missing Value Handling ---\")\n",
    "        print(f\"Air Quality UCL Dataset: Initial rows: {initial_rows}, Dropped rows: {dropped_rows}, (Remaining: {len(df_air)} rows)\\n\")\n",
    "        return df_air\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: One or more dataset files not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "#Column Selecting\n",
    "#Step 1.2 — Prepare the Data\n",
    "def column_selecting(df_air):\n",
    "    features = ['T', 'RH', 'AH']\n",
    "    target = 'CO(GT)'\n",
    "    features = df_air[features]\n",
    "    target = df_air[target]\n",
    "    #test_size = 0.3 splits test into training (70%) and testing (30%).\n",
    "    #random_state = 42\n",
    "    #The random_state = 42 parameter sets a seed for the random number generator.\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "    print(\"--- Train/Test Split Dimensions ---\")\n",
    "    print(f\"Training Features (features_train) Shape: {features_train.shape}\")\n",
    "    print(f\"Testing Features (features_test) Shape: {features_test.shape}\")\n",
    "    print(f\"Training Target (target_train) Shape: {target_train.shape}\")\n",
    "    print(f\"Testing Testing (target_test) Shape: {target_test.shape}\")\n",
    "    print(\"--- Splitting Complete ---\")\n",
    "    return features_train, features_test, target_train, target_test\n",
    "\n",
    "#Step 2 — Fit Models of Increasing Complexity\n",
    "def linear_reg(features_train, features_test, target_train, target_test):\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    degrees = range(1, 11)\n",
    "\n",
    "    for d in degrees:\n",
    "        poly_model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=d, include_bias=False)),\n",
    "            ('lin_reg', LinearRegression())\n",
    "        ])\n",
    "        poly_model.fit(features_train, target_train)\n",
    "        target_train_pred = poly_model.predict(features_train)\n",
    "        target_test_pred = poly_model.predict(features_test)\n",
    "        train_rmse = np.sqrt(mean_squared_error(target_train, target_train_pred))\n",
    "        test_rmse = np.sqrt(mean_squared_error(target_test, target_test_pred))\n",
    "        train_errors.append(train_rmse)\n",
    "        test_errors.append(test_rmse)\n",
    "\n",
    "        print(f\"Model Degree {d:2}: Training RMSE = {train_rmse:.4f}, Testing RMSE = {test_rmse:.4f}\")\n",
    "    print(\"--- All 10 models have been trained successfully. ---\")\n",
    "    return degrees, train_errors, test_errors\n",
    "\n",
    "#Step 3 — Plot the Validation Curve\n",
    "def Validation_Curve(degrees, train_errors, test_errors):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, train_errors, label='Training RMSE', marker='o')\n",
    "    plt.plot(degrees, test_errors, label='Testing RMSE', marker='o')\n",
    "    plt.xlabel('Model Complexity (Polynomial Degree)')\n",
    "    plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "    plt.title('Bias–Variance Tradeoff')\n",
    "    plt.xticks(list(degrees))\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    min_test_error_index = test_errors.index(min(test_errors))\n",
    "    optimal_degree = list(degrees)[min_test_error_index]\n",
    "    min_error = min(test_errors)\n",
    "    plt.axvline(x=optimal_degree, color='g', linestyle='--', linewidth=1.5, label='Optimal Complexity')\n",
    "    plt.annotate(f'Optimal Degree: {optimal_degree}',\n",
    "                 xy=(optimal_degree, min_error),\n",
    "                 xytext=(optimal_degree + 1, min_error * 0.9),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05, width=0.5),\n",
    "                 fontsize=10)\n",
    "    plt.text(1.5, max(test_errors) * 0.9, 'UNDERFITTING\\n(High Bias)', color='red', fontsize=12,\n",
    "             horizontalalignment='center')\n",
    "    plt.text(8.5, max(test_errors) * 0.9, 'OVERFITTING\\n(High Variance)', color='blue', fontsize=12,\n",
    "             horizontalalignment='center')\n",
    "    plt.savefig(\"validation_curve.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#Extra 4.1 - Plotting Graphs\n",
    "\n",
    "def generate_analysis_plots(degrees, train_errors, test_errors, n_features_original=3):\n",
    "    feature_counts = [int(comb(n_features_original + d, d) - 1) for d in degrees]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, feature_counts, label='Total Polynomial Features', marker='o', color='purple')\n",
    "    plt.title('1. Model Complexity Growth (Feature Count vs. Degree)')\n",
    "    plt.xlabel('Polynomial Degree (d)')\n",
    "    plt.ylabel('Number of Features Created (Log Scale)')\n",
    "    plt.xticks(list(degrees))\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"complexity_growth_analysis.png\")\n",
    "    plt.show()\n",
    "\n",
    "    generalization_gap = np.array(test_errors) - np.array(train_errors)\n",
    "    optimal_degree = degrees[np.argmin(test_errors)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, generalization_gap, label='Testing RMSE - Training RMSE', marker='o', color='red')\n",
    "    plt.axhline(0, color='gray', linestyle='--')\n",
    "    plt.axvline(optimal_degree, color='g', linestyle='--', label=f'Optimal Degree: {optimal_degree}')\n",
    "    plt.title('2. Overfitting Indicator: Generalization Gap')\n",
    "    plt.xlabel('Polynomial Degree (d)')\n",
    "    plt.ylabel('Generalization Gap (Variance)')\n",
    "    plt.xticks(list(degrees))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"overfitting_indicator_analysis.png\")\n",
    "    plt.show()\n",
    "\n",
    "#Extra 4.2 - Plotting Graphs\n",
    "def plot_residual_analysis(optimal_degree, features_train, target_train, features_test, target_test):\n",
    "    optimal_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=optimal_degree, include_bias=False)),\n",
    "        ('lin_reg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    optimal_model.fit(features_train, target_train)\n",
    "\n",
    "    y_test_pred = optimal_model.predict(features_test)\n",
    "    residuals = target_test - y_test_pred\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "    plt.hlines(y=0, xmin=min(y_test_pred), xmax=max(y_test_pred), color='red', linestyle='--')\n",
    "    plt.title(f'3. Residual Plot for Optimal Model (Degree {optimal_degree})')\n",
    "    plt.xlabel('Predicted CO(GT) Value')\n",
    "    plt.ylabel('Residuals (Actual - Predicted)')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"residual_plot_analysis.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Extra 5.1 - Cross Validation\n",
    "def cross_val_analysis(df_air):\n",
    "    X = df_air[['T', 'RH', 'AH']]\n",
    "    y = df_air['CO(GT)']\n",
    "    degrees = range(1, 11)\n",
    "    cv_rmses = []\n",
    "    print()\n",
    "    print(\"--- Cross-Validation Analysis (k=5) ---\")\n",
    "    for d in degrees:\n",
    "        # Pipeline oluşturulur\n",
    "        poly_model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=d, include_bias=False)),\n",
    "            ('lin_reg', LinearRegression())\n",
    "        ])\n",
    "        scores = cross_val_score(\n",
    "            poly_model,\n",
    "            X,\n",
    "            y,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=5\n",
    "        )\n",
    "        avg_rmse = np.mean(np.sqrt(-scores))\n",
    "        cv_rmses.append(avg_rmse)\n",
    "        print(f\"Model Degree {d:2}: Average CV RMSE = {avg_rmse:.4f}\")\n",
    "\n",
    "    optimal_degree_cv = degrees[np.argmin(cv_rmses)]\n",
    "    min_cv_rmse = np.min(cv_rmses)\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Optimal Degree (CV): {optimal_degree_cv} (Min CV RMSE: {min_cv_rmse:.4f})\")\n",
    "    print(\"-\" * 40)\n",
    "    return degrees, cv_rmses\n",
    "\n",
    "#Extra 5.2 - Cross Validation Plot\n",
    "def plot_cv_validation_curve(degrees, cv_rmses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(degrees, cv_rmses, label='Average CV RMSE (k=5)', marker='o', color='darkorange')\n",
    "\n",
    "    optimal_degree_cv = degrees[np.argmin(cv_rmses)]\n",
    "    min_error = np.min(cv_rmses)\n",
    "\n",
    "    plt.axvline(x=optimal_degree_cv, color='red', linestyle='--', linewidth=1.5,\n",
    "                label=f'CV Optimal Degree: {optimal_degree_cv}')\n",
    "\n",
    "    plt.title('Validation Curve: Cross-Validation Error')\n",
    "    plt.xlabel('Model Complexity (Polynomial Degree)')\n",
    "    plt.ylabel('Average Root Mean Squared Error (RMSE)')\n",
    "    plt.xticks(list(degrees))\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cv_validation_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "#Extra 5.4 - Comparison\n",
    "def compare(optimal_degree,optimal_degree_cv):\n",
    "    print(\"\\n=== FINAL MODEL COMPARISON ===\")\n",
    "    print(f\"1. Single Split Optimal Degree: {optimal_degree}\")\n",
    "    print(f\"2. Cross-Validation Optimal Degree: {optimal_degree_cv}\")\n",
    "    print(\"\\nCOMMENT:\")\n",
    "    if optimal_degree_cv < optimal_degree:\n",
    "        print(f\"Cross-Validation (CV) showed a significant shift toward simplicity (Degree {optimal_degree_cv}).\")\n",
    "        print(\"This indicates that the single split result (Degree {optimal_degree}) was overly optimistic.\")\n",
    "        print(\n",
    "            \"CV proves that higher-degree models are unstable and highly prone to High Variance/Overfitting when tested on different data partitions.\")\n",
    "    elif optimal_degree_cv == optimal_degree:\n",
    "        print(\n",
    "            \"Both analysis methods agree on the optimal complexity. This indicates the model is highly stable across different data splits.\")\n",
    "    else:\n",
    "        print(f\"CV suggests a slightly more complex model (Degree {optimal_degree_cv}) is optimal.\")\n",
    "        print(\n",
    "            \"This means the single split analysis was pessimistic, and CV found a better average fit through wider testing.\")\n",
    "\n",
    "    print(\"==============================\")\n",
    "\n",
    "def main():\n",
    "    df_air = load_data(air_path)\n",
    "    features_train, features_test, target_train, target_test = column_selecting(df_air)\n",
    "    degrees, train_errors, test_errors = linear_reg(features_train, features_test, target_train, target_test)\n",
    "    test_errors_array = np.array(test_errors)\n",
    "    optimal_index = np.argmin(test_errors_array)\n",
    "    optimal_degree = degrees[optimal_index]\n",
    "    print(f\"\\nFINAL SPLIT ANALYSIS: Optimal Degree is {optimal_degree} (Min Test RMSE: {test_errors[optimal_index]:.4f})\")\n",
    "    Validation_Curve(degrees, train_errors, test_errors)\n",
    "    generate_analysis_plots(degrees, train_errors, test_errors)\n",
    "    plot_residual_analysis(\n",
    "        optimal_degree,\n",
    "        features_train,\n",
    "        target_train,\n",
    "        features_test,\n",
    "        target_test\n",
    "    )\n",
    "    degrees_cv, cv_rmses = cross_val_analysis(df_air)\n",
    "    optimal_degree_cv = degrees_cv[np.argmin(cv_rmses)]\n",
    "    plot_cv_validation_curve(degrees_cv, cv_rmses)\n",
    "    compare(optimal_degree,optimal_degree_cv)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}